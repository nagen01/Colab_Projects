{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_fine_tuning_sent_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNG3oacUoggTiHKRSI7x5zf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa31c071a7cb43368dab5fb60a137d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_81b40aa75ec647f185d08d6ed61a454c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da21894acdf64545bc3cc4853e12b7d2",
              "IPY_MODEL_c19077dff3f34497bf4ab0332dabca61"
            ]
          }
        },
        "81b40aa75ec647f185d08d6ed61a454c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da21894acdf64545bc3cc4853e12b7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ccd2e8595a6c474c8314905bc35cc903",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cf2069c9e264e269d0e2b334f09becc"
          }
        },
        "c19077dff3f34497bf4ab0332dabca61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ee995328d494c33b6a7b9047d230374",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 2.64MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7e6b2ef0c594f32bca6a473f9564854"
          }
        },
        "ccd2e8595a6c474c8314905bc35cc903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cf2069c9e264e269d0e2b334f09becc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ee995328d494c33b6a7b9047d230374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7e6b2ef0c594f32bca6a473f9564854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f7227e57d59412aaafca9770f929357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b61ade45736845829cc0ef834f8b8f1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e06f942d5cc4f9b9cc38d3b30966504",
              "IPY_MODEL_610be21cc7df4b0a9d46f5755a582036"
            ]
          }
        },
        "b61ade45736845829cc0ef834f8b8f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e06f942d5cc4f9b9cc38d3b30966504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41dce2f8743e4d4db499b9698fc953fc",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96b258265fad48fe96b324676c747cc7"
          }
        },
        "610be21cc7df4b0a9d46f5755a582036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_92f925d3467d4115b2edea6bff1340e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 16.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_529ff3c571f54283834a663256599aa7"
          }
        },
        "41dce2f8743e4d4db499b9698fc953fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96b258265fad48fe96b324676c747cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92f925d3467d4115b2edea6bff1340e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "529ff3c571f54283834a663256599aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "220bac50cc4f493aa1fa009ab4fcf1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04dee65f2fbc4981882257e5c2431cfe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_16882841c1054bf3a6fdc17b8f002cdd",
              "IPY_MODEL_28c8f70605d747e4a24b99af901b24c5"
            ]
          }
        },
        "04dee65f2fbc4981882257e5c2431cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16882841c1054bf3a6fdc17b8f002cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_58af9be8764242bc93564a3e72d2d381",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7073bbe69a2e4779a408ce03c0b449a7"
          }
        },
        "28c8f70605d747e4a24b99af901b24c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0db3e7c31d9043049ebfbe39d377a700",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:06&lt;00:00, 68.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5291d94480fd45c6937210332d1905f3"
          }
        },
        "58af9be8764242bc93564a3e72d2d381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7073bbe69a2e4779a408ce03c0b449a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0db3e7c31d9043049ebfbe39d377a700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5291d94480fd45c6937210332d1905f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagen01/Colab_Projects/blob/master/bert_fine_tuning_sent_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K14EgAMhdF5Y",
        "colab_type": "code",
        "outputId": "467ad94f-db15-4bb4-c957-c87ab5b72f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Get device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at {}.'.format(device_name))\n",
        "else:\n",
        "  raise SystemError(\"GPU device not found\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at /device:GPU:0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaX792pNpmeZ",
        "colab_type": "code",
        "outputId": "d0551591-b521-4d61-e1e0-afcafdd49360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Verifying GPU with Pytorch:\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  #Tell pytorch to use GPU\n",
        "  device = torch.device('cuda')\n",
        "  print(\"There are %d GPU(s) available \" % torch.cuda.device_count())\n",
        "  print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print(\"No GPU available, using CPU instead\")\n",
        "  device = torch.device('cpu')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available \n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8y4TreZtWc1",
        "colab_type": "code",
        "outputId": "8418da77-3fcc-4009-c364-f194789bef8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\r\u001b[K     |▊                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 29.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 30.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 35.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 24.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 19.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 21.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 19.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 15.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 16.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 15.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 15.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 15.7MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 15.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 15.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 15.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 15.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 20.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=f366d58b170fe7c6b604ecffa84058cde577b151c0030861671d4869b7f2bd6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJLNrvPvIAER",
        "colab_type": "code",
        "outputId": "bb0f5118-39ee-437c-983a-f2be868f33ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=1c92895837b4846d08dde33bdf59970e8dc160c2b64a7e14d755724107552e10\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2OnAI9fvr0P",
        "colab_type": "code",
        "outputId": "9e9d4a47-9c6c-4b96-bae0-056df84a4e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Downloading the dataset\")\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "#if os.path.exists('./cola_public_1.1.zip'):\n",
        "wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading the dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./cola_public_1.1.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDW83QChvlOv",
        "colab_type": "code",
        "outputId": "47d79136-3655-49d6-d24e-c49e727ded6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "#Unzip the file\n",
        "if not os.path.exists('./cola_public/'):\n",
        "  !unzip cola_public_1.1.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvIjkYJpI8vZ",
        "colab_type": "code",
        "outputId": "4ae73871-3964-47c0-82fd-ba497875a285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/cola_public/raw/in_domain_train.tsv',sep='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "print(\"Number of training samples: {}\".format(df.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 8551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQy6tPowTgL",
        "colab_type": "code",
        "outputId": "460177bc-dae1-4f89-8fb1-9064301832c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "print(\"Printing top 10 rows:\")\n",
        "print(df.head())\n",
        "print('\\n'*2)\n",
        "print(\"Printing random 10 rows:\")\n",
        "print(df.sample(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing top 10 rows:\n",
            "  sentence_source  ...                                           sentence\n",
            "0            gj04  ...  Our friends won't buy this analysis, let alone...\n",
            "1            gj04  ...  One more pseudo generalization and I'm giving up.\n",
            "2            gj04  ...   One more pseudo generalization or I'm giving up.\n",
            "3            gj04  ...     The more we study verbs, the crazier they get.\n",
            "4            gj04  ...          Day by day the facts are getting murkier.\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "\n",
            "\n",
            "\n",
            "Printing random 10 rows:\n",
            "     sentence_source  ...                                           sentence\n",
            "2226            l-93  ...                          This knife cut the bread.\n",
            "7672           sks13  ...                    John believes it to be raining.\n",
            "1829            r-67  ...  I don't know the boy the flowers who Mary gave...\n",
            "1680            r-67  ...  It is this hat that it is certain that he was ...\n",
            "3627            ks08  ...                                 Where did he look?\n",
            "24              gj04  ...                  Harry coughed himself into a fit.\n",
            "2415            l-93  ...                      $ 100,000 will build a house.\n",
            "891             bc01  ...  If Ron knows whether to wear a tuxedo, and Cas...\n",
            "4144            ks08  ...         You is the only person that I can rely on.\n",
            "1264            r-67  ...  I screamed at some children who were watching me.\n",
            "\n",
            "[10 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8L45q51zxWm",
        "colab_type": "code",
        "outputId": "5e212fad-5e98-479f-ed25-e1405f2f057a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "#We need to focus on sentence and lable (Sentence is gramatically correct or not)\n",
        "#Let's find 10 random training samples that are gramatically incorrect\n",
        "df.loc[df.label == 0].sample(10)[['sentence','label']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2957</th>\n",
              "      <td>He turned from a prince.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5925</th>\n",
              "      <td>Jennie smiled the sandwich.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3218</th>\n",
              "      <td>I gushed the fountain.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>The fatter he goes to a doctor when he gets th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>John would be hated to win.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1567</th>\n",
              "      <td>It never occurred to Harvey because he is inse...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1205</th>\n",
              "      <td>Who does Phineas know a girl who is working with?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>His expectations lower, the higher the stakes.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5803</th>\n",
              "      <td>Two or boring books take a very long time to r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3250</th>\n",
              "      <td>Tony bent at the rod.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "2957                           He turned from a prince.      0\n",
              "5925                        Jennie smiled the sandwich.      0\n",
              "3218                             I gushed the fountain.      0\n",
              "185   The fatter he goes to a doctor when he gets th...      0\n",
              "503                         John would be hated to win.      0\n",
              "1567  It never occurred to Harvey because he is inse...      0\n",
              "1205  Who does Phineas know a girl who is working with?      0\n",
              "168      His expectations lower, the higher the stakes.      0\n",
              "5803  Two or boring books take a very long time to r...      0\n",
              "3250                              Tony bent at the rod.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc75S6Ay1a79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's extract sentences and labels from training data\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB-rr3Fk2Lbu",
        "colab_type": "code",
        "outputId": "f55ce465-13cc-4eb4-c9fb-9f5c5a90dc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8551,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fn08j0R2YYV",
        "colab_type": "text"
      },
      "source": [
        "#Tokenization and formatting\n",
        "In this section we will tokenize the sentence and format the things in which BERT model can understand the input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFZgFDaB2ssz",
        "colab_type": "text"
      },
      "source": [
        "#Bert Tokenization\n",
        "To feed into BERT, sentence must be broken into tokens and tokens must be mapped to their index in the tokenizer vocabulary\n",
        "\n",
        "Tokenization must be performed by tokenizer (bert-....). Here we will use \"bert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kqjp3ir2NDr",
        "colab_type": "code",
        "outputId": "4796ac73-8da8-4ef0-be64-8abe6258ffff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "fa31c071a7cb43368dab5fb60a137d39",
            "81b40aa75ec647f185d08d6ed61a454c",
            "da21894acdf64545bc3cc4853e12b7d2",
            "c19077dff3f34497bf4ab0332dabca61",
            "ccd2e8595a6c474c8314905bc35cc903",
            "4cf2069c9e264e269d0e2b334f09becc",
            "8ee995328d494c33b6a7b9047d230374",
            "b7e6b2ef0c594f32bca6a473f9564854"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "#Load the tokenizer\n",
        "print(\"Loading the bert tokenizer.........\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading the bert tokenizer.........\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa31c071a7cb43368dab5fb60a137d39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPm7Q8AR4FtF",
        "colab_type": "text"
      },
      "source": [
        "Let's apply the tokenizer on single sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GboU4uq_3g7k",
        "colab_type": "code",
        "outputId": "f8041e7b-9bfc-4470-bf76-0363d0ac606a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(f\"Original_sentence: {sentences[0]}\")\n",
        "#Tokenize\n",
        "print(f\"Tokenized_words: {tokenizer.tokenize(sentences[0])}\")\n",
        "#Mapping tokens to their respective ids\n",
        "print(f\"Token_ids: {tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0]))}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original_sentence: Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized_words: ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token_ids: [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g06kGhUo5iAl",
        "colab_type": "text"
      },
      "source": [
        "The above 2 steps can be combined into one as below:\n",
        "tokenize_encode = tokenize + convert_tokens_to_ids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O1K8nPO4T97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(f\"Token_ids in one step by tokenize.encode: {tokenizer.tokenize.encode(sentences[0])}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4ki7uz_8KvI",
        "colab_type": "text"
      },
      "source": [
        "##Required formatting\n",
        "1. Add special tokens at start and end of each sentence\n",
        "2. Pad/Truncate all sentences to a single constant length\n",
        "3. Explicitly differienciate real tokens from padding tokens with \"Attention_mask\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRyJ3UcG9KiY",
        "colab_type": "text"
      },
      "source": [
        "#Addition of special tokens \n",
        "At the starting ([CLS]) and at the end ([SEP]) of each sentence.\n",
        "\n",
        "[SEP] : Appended at last of each sentence, It try to tell the question asked in 2nd sentence is present in 1st sentence? (Relation).\n",
        "Still doubt: Why this is used in case of single sentence aswell?\n",
        "\n",
        "[CLS] : Pretended at the starting of each sequence(not necessarily sentence).\n",
        "\n",
        "BERT contains 12 transformer layers, each transformer takes a list of token embeddings and produce the same number of embeddings on the output (Feature values changed)\n",
        "\n",
        "On the output of the final transformer(12th) only first embedding (corrosponding to the [CLS] token) is used by the classifier. \"The first token of every sequence is always a special classification token ([CLS]). The final hidden state corresponding to this token is used as the aggregate sequence representation for classification tasks.\" (from the BERT paper)\n",
        "\n",
        "ie. BERT is trained to use only this [CLS] token for classification, we know that the model has been motivated to encode everything it needs for the classification step into that single 768 value embeding vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQhKQsK5CT0c",
        "colab_type": "text"
      },
      "source": [
        "#Sentence length and Attention mask\n",
        "The sentences in our dataset always has varrying lenght, to handle this BERT has 2 constraints:\n",
        "\n",
        "1. All sentences must be padded or truncated to single fixed lenght.\n",
        "2. The maximum sentence length is 512 tokens.\n",
        "\n",
        "Padding is done with special char [PAD], which is at index \"0\" in BERT vocabulary.\n",
        "\n",
        "Padding impact both model speed and accuracy...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U68tjjATRRMd",
        "colab_type": "text"
      },
      "source": [
        "#Sentence to ids\n",
        "\n",
        "The tokenizer.encode combines multiple steps\n",
        "1. Split sentence into tokens\n",
        "2. Add special [CLS] and [SEP] tokens\n",
        "3. Map the tokens to their ids\n",
        "\n",
        "*** This Function can perform truncating but not capable of handling padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvv2fGCO6SBF",
        "colab_type": "code",
        "outputId": "490711d8-3228-4722-cdf8-89a0b384c59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#Tokenize all the sentences and mapping to their tokens:\n",
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "  #encode will:\n",
        "  #1. Tokenize the sentence\n",
        "  #2. Pretend [CLS]\n",
        "  #3. Append [SEP]\n",
        "  #4. Convert tokens to their respective IDs.\n",
        "  encoded_sent = tokenizer.encode(\n",
        "      sent,                          #Sentence to encode \n",
        "      add_special_tokens=True,       #Add [CLS] and [SEP]\n",
        "      #This function also support truncation and conversion to pytorch tensors \n",
        "      #but we need padding hence can't use these features.\n",
        "      #max_length = 128,             #Truncate all the sentences\n",
        "      #return_tensors = 'pt'         #Return pytorch tensors \n",
        "      )\n",
        "  #Add encoded sentence to the list\n",
        "  input_ids.append(encoded_sent)\n",
        "\n",
        "#Print sentence[0] for original and IDs\n",
        "print(f\"Original Sentence: {sentences[0]}\")\n",
        "print(f\"Token IDs: {input_ids[0]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence: Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ftChIyZVBO1",
        "colab_type": "text"
      },
      "source": [
        "##Padding and Truncating:\n",
        "\n",
        "Pad/truncate all the sentence so that all have same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm95vwgXUiIu",
        "colab_type": "code",
        "outputId": "4c5b105c-f3f2-4f75-fbfd-3857bb05fecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Find the sentence with maximum length:\n",
        "print(f\"Maximum length of the sentence in list: {max([len(sen) for sen in input_ids])}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length of the sentence in list: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k59vGNyXVeIf",
        "colab_type": "code",
        "outputId": "0aacb001-69e1-4ee5-e666-1bb516621d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#Here we find maximum length as 47, let's take maximum length as 64 \n",
        "max_length = 64\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"\\n Padding/Truncating all sentences to %d values...\" % max_length)\n",
        "print('\\n Padding_token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input values with 0\n",
        "# 'post' indicate that we want to pad or truncate at the end of the sentence as opposed to the beginning\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen = max_length, padding = 'post', \n",
        "                          truncating = 'post', dtype = 'long', value = 0)\n",
        "\n",
        "print('\\n Done')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Padding/Truncating all sentences to 64 values...\n",
            "\n",
            " Padding_token: \"[PAD]\", ID: 0\n",
            "\n",
            " Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoQtjo0fnwJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HUBVbQB3v26",
        "colab_type": "text"
      },
      "source": [
        "#Attention mask:\n",
        "The attention mask make it explicit which token is actual words Vs. which are padding.\n",
        "The BERT vocabulary dosen't use ID = \"0\", so if ID is equal to \"0\" then it's padding otherwise real word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al975IpE3bS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating attention mask\n",
        "attention_masks = []\n",
        "\n",
        "for sent in input_ids:\n",
        "  #Create attention mask\n",
        "  #If token id is 0, then it's padding and set the attention mask to 0.\n",
        "  #If token id is non zero, then it's actual word and set the attention mask to 1.\n",
        "\n",
        "  attn_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "  #For understanding:\n",
        "  \n",
        "  #if token_id = 7\n",
        "  #print(token_id > 0)    will print \"True\"\n",
        "  #print(int(token_id > 0))   will print \"1\"\n",
        "\n",
        "  #if token_id = 0\n",
        "  #print(token_id > 0)    will print \"False\"\n",
        "  #print(int(token_id > 0))   will print \"0\"\n",
        "\n",
        "\n",
        "  #Store the attention mask for this sentence\n",
        "  attention_masks.append(attn_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCSGP2whtuuu",
        "colab_type": "text"
      },
      "source": [
        "#Training and validation:\n",
        "Divide into training (90%) and test(10%) data\n",
        "\n",
        "Now we have extracted id's and attentio mask, as per requirement of BERT model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gL6tI63r19L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Splitting the token_ids (90:10):\n",
        "train_input_id, val_input_id, train_labels, val_labels = train_test_split(input_ids, labels,\n",
        "                                                                            test_size=0.1, random_state=2018 )\n",
        "\n",
        "#Splitting the attention mask (90:10):\n",
        "train_mask, validation_mask, _, _  = train_test_split(attention_masks, labels,\n",
        "                                                      test_size=0.1, random_state=2018 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-0Xs_IdPzoF",
        "colab_type": "code",
        "outputId": "17c8f3ec-e49d-4089-d47d-4edfa615c04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "print(len(input_ids))\n",
        "print(len(labels))\n",
        "print(labels[0])\n",
        "print(len(train_input_id))\n",
        "print(train_input_id[0])\n",
        "print(len(val_input_id))\n",
        "print(len(train_labels))\n",
        "print(len(val_labels))\n",
        "print(len(train_mask))\n",
        "print(train_mask[0])\n",
        "print(len(validation_mask))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8551\n",
            "8551\n",
            "1\n",
            "7695\n",
            "[ 101 2002 2939 1996 3328 1012  102    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "856\n",
            "7695\n",
            "856\n",
            "7695\n",
            "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weZRPKXpwkC2",
        "colab_type": "text"
      },
      "source": [
        "#Converting to pytorch data types:\n",
        " BERT model expects PyTorch tensors rather than numpy.ndarrays, hence converting all dataset variables into pytorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiEY3Neas62w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_id = torch.tensor(train_input_id)\n",
        "val_input_id = torch.tensor(val_input_id)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "\n",
        "train_mask = torch.tensor(train_mask)\n",
        "validation_mask = torch.tensor(validation_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BQn1rbnQ-W_",
        "colab_type": "code",
        "outputId": "af2ce34a-732c-4fd2-8a93-6f36f11711f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "print(train_input_id[0])\n",
        "print(val_input_id[0])\n",
        "print(train_labels[0])\n",
        "print(val_labels[0])\n",
        "print(train_mask[0])\n",
        "print(validation_mask[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 101, 2002, 2939, 1996, 3328, 1012,  102,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "tensor([  101,  1996, 13176,  3369,  2035,  1012,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(1)\n",
            "tensor(0)\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7QwnJRz1IKv",
        "colab_type": "text"
      },
      "source": [
        "We also need to create an iterator for our dataset using the torch DataLoader class which helps save on memory during training because, unlike for a loop, with an iterator the entire dataset dose not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-K6vb1sxkvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL68drSl23to",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataloader need to know our batch size for training so we specify it here\n",
        "#For fine tuning BERT on specific task, authors recommend a batch size of 16 or 32\n",
        "\n",
        "#Let's take batch size of 32\n",
        "batch_size = 32\n",
        "\n",
        "#Create DataLoader for our training set:\n",
        "train_data = TensorDataset(train_input_id, train_mask, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "#Create DataLoader for our validation set:\n",
        "validation_data = TensorDataset(val_input_id, validation_mask, val_labels)\n",
        "validation_sampler = RandomSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler = validation_sampler, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFoWaZIQPS2M",
        "colab_type": "code",
        "outputId": "4c4e0275-58a1-4f54-b184-6727c0ab98b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "source": [
        "print(len(train_data[0]))\n",
        "print(train_data[0])\n",
        "print(len(train_data))\n",
        "print(\"Since we have taken batch size as 32, 7695/32 ~= 241\")\n",
        "print(f\"During training {len(train_dataloader)} samples will be loaded during each batch run\")\n",
        "\n",
        "print(len(validation_data[0]))\n",
        "print(validation_data[0])\n",
        "print(len(validation_data))\n",
        "print(\"Since we have taken batch size as 32, 856/32 ~= 27\")\n",
        "print(f\"During validation {len(validation_dataloader)} samples will be doaded during each batch cycle\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "(tensor([ 101, 2002, 2939, 1996, 3328, 1012,  102,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor(1))\n",
            "7695\n",
            "Since we have taken batch size as 32, 7695/32 ~= 241\n",
            "During training 241 samples will be loaded during each batch run\n",
            "3\n",
            "(tensor([  101,  1996, 13176,  3369,  2035,  1012,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0]), tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor(0))\n",
            "856\n",
            "Since we have taken batch size as 32, 856/32 ~= 27\n",
            "During validation 27 samples will be doaded during each batch cycle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "astL3eCv5F3T",
        "colab_type": "text"
      },
      "source": [
        "##Train our classification Model\n",
        "Now data is properly formatted and we can proceed for training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZygcfXDa5aC0",
        "colab_type": "text"
      },
      "source": [
        "#BertForSequenceClassification\n",
        "For this task first we want modify the pretrained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well suited for our task\n",
        "\n",
        "The Huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of trained BERT model, each has different top layers and output types designed to accomodate their specific NLP tasks.\n",
        "\n",
        "Current list of classes provided for fine tuning:\n",
        "BertModel\n",
        "BertForPreTraining\n",
        "BertForMaskedLM\n",
        "BertForNextSentencePrediction\n",
        "BertForSequenceClassification\n",
        "BertForTokenClassification\n",
        "BertForQuestionAnswering\n",
        "\n",
        "We will be using BertForSequenceClassification, This is normal Bert model with an added single layer on top of classification that we will use as sentence classifier. As we feed training data the entire pre_trained Bert model and the additional untrained classification layer is trained on our specific task.\n",
        "\n",
        "\"bert-base-uncased\" : Has only lowercase letters and is smaller version of the two (\"base\" Vs \"large\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE0b36ku3zM4",
        "colab_type": "code",
        "outputId": "2c86c0f9-86d4-4a85-dbf3-061f1a846838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f7227e57d59412aaafca9770f929357",
            "b61ade45736845829cc0ef834f8b8f1f",
            "5e06f942d5cc4f9b9cc38d3b30966504",
            "610be21cc7df4b0a9d46f5755a582036",
            "41dce2f8743e4d4db499b9698fc953fc",
            "96b258265fad48fe96b324676c747cc7",
            "92f925d3467d4115b2edea6bff1340e2",
            "529ff3c571f54283834a663256599aa7",
            "220bac50cc4f493aa1fa009ab4fcf1be",
            "04dee65f2fbc4981882257e5c2431cfe",
            "16882841c1054bf3a6fdc17b8f002cdd",
            "28c8f70605d747e4a24b99af901b24c5",
            "58af9be8764242bc93564a3e72d2d381",
            "7073bbe69a2e4779a408ce03c0b449a7",
            "0db3e7c31d9043049ebfbe39d377a700",
            "5291d94480fd45c6937210332d1905f3"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "#Load the BertForSequentialClassification, the pretrained BERT model with a single linear classification layer on top\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',       #Uses the 12 layer BERT model with an uncased vocab.\n",
        "    num_labels = 2,            #The number of outut labels = 2 for binary classification, it can be increased for multi_class task\n",
        "    output_attentions = False,  #Whether the model returns the attention mask\n",
        "    output_hidden_states = False # Whether the model return the hidden states\n",
        ")\n",
        "\n",
        "#Tell the pytorch model to run on GPU:\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f7227e57d59412aaafca9770f929357",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "220bac50cc4f493aa1fa009ab4fcf1be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCM7ezkeQPDq",
        "colab_type": "text"
      },
      "source": [
        "We can browse all the model's parameters by name here\n",
        "\n",
        "1. The embedding layer\n",
        "2. The first of the twelve transformers\n",
        "3. The output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoQLqmleCTu5",
        "colab_type": "code",
        "outputId": "df62ea79-d2c9-4b5c-fbde-da3bbd2113ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "#Get all of the model parameters as a list of tuples:\n",
        "params = list(model.named_parameters())\n",
        "print(\"The Bert model has {:}  different named parameters:\\n\".format(len(params)))\n",
        "\n",
        "print(\"\\n=====Embedding Layer========\\n\")\n",
        "for p in params[0:5]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print(\"\\n===First out of 12 transformers====\\n\")\n",
        "for p in params[5:21]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "                                               \n",
        "print(\"\\n=====Output Layer========\\n\")\n",
        "for p in params[-4:]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))                                     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Bert model has 201  different named parameters:\n",
            "\n",
            "\n",
            "=====Embedding Layer========\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "===First out of 12 transformers====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "=====Output Layer========\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtXanzytS-Dn",
        "colab_type": "text"
      },
      "source": [
        "#Optimizer and Learning rate scheduler:\n",
        "Now model is loaded and we need to get training parameters from within the stored model.\n",
        "\n",
        "For the purpose of fine_tuning, the authors recommend to choose below values:\n",
        "1. Batch size: 16 or 32 (we choose 32 when creating dataloader)\n",
        "2. Learning rate(Adam): 5e-5, 3e-5, 2e-5 (We will use 2e-5)\n",
        "3. Number of epoch: 2,3 or 4 (We will use 4)\n",
        "\n",
        "Note: The epsilon parameter eps = 1e-8 is \"a very small number to prevent any division by zero in the implementation\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKO1z5rOr4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Note: AdmW is a class from huggingface library (Oppossed to pytorch)\n",
        "#W stands for Weight decay fix.\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                 lr = 2e-5,     #arg.learning_rate -default is 5e-5, we are using 2e-5\n",
        "                 eps = 1e-8     #arg.adam_epsilon default is 1e-8\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZq-Z5l1WGK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "#Number of epoch\n",
        "epochs = 4\n",
        "\n",
        "#Total number of training set is number of batches * number of epoch\n",
        "total_steps = len(train_dataloader)*epochs\n",
        "\n",
        "#Create learning rate scheduler:\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, #Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps\n",
        "                                            )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsFLIEpGXbix",
        "colab_type": "text"
      },
      "source": [
        "#Training loop:\n",
        "Lot more is going on, fundamently for each pass in our loop we have a training phase and validation phase and hence at each pass we need to:\n",
        "\n",
        "Training Loop:\n",
        "\n",
        "\n",
        "1. Unlock our data inputs and labels.\n",
        "2. Load data on gpu for accelaration.\n",
        "3. Clear out gradient calculated at previous pass (In pytorch gradient calculated by default which is useful for things like RRN's unless we explecitely clear them out).\n",
        "4. Forward pass (Feed input data through the network).\n",
        "5. Backword pass (Backword propogation).\n",
        "6. Tell the network to update the parameters with optimizer.step().\n",
        "7. Track variables for monitoring the progress.\n",
        "\n",
        "Evaluation Loop:\n",
        "1. Unpack our data inputs and labels\n",
        "2. Load data on gpu for accelaration\n",
        "3. Forward pass(Feed input data through the network)\n",
        "4. Compute loss on our validation data and track variabls for monitoring purposes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Q_EUtkXPxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating helper function for calculating the accuracy:\n",
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat)/len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSO-EBABa6ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Helper function for formatting elapse time:\n",
        "import time \n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  #Takes time in seconds and returns in hh:mm:ss format\n",
        "  #Round to nearest second\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "\n",
        "  #Format as hh:mm:ss\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrkpJM4db1NC",
        "colab_type": "text"
      },
      "source": [
        "Ready for kicking off the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EnIH7b0b0KR",
        "colab_type": "code",
        "outputId": "26ed75d1-5e69-4a3f-b05d-0fa9007f58ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "#This training code is based on run_glue.py (Huggingface)\n",
        "\n",
        "#Set the seed value all over the places to make it reproducible\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "#Store the average loss after each epochs so that we can plot it\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "  #\n",
        "  #=========Training==========#\n",
        "  #\n",
        "\n",
        "  #perform full pass over the training set\n",
        "  print(\"\")\n",
        "  print(\"========= Epoch {:}/{:} =========\".format(epoch_i + 1, epochs))\n",
        "  print(\"==== Training......\")\n",
        "\n",
        "  #Measure how long the training epoch take time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #Reset the total loss for this epoch\n",
        "  total_loss = 0\n",
        "\n",
        "  #Put the model into training mode\n",
        "  model.train()  #Here \"train\" only change the mode into training and it dosen't perform training\n",
        "  \n",
        "  #Note: dropout and batchnorm perform differently during training and testing\n",
        "\n",
        "  #For each batch in your training data:\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    #progress update every 40 batches\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      #Calculate elapsed time in minutes:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      #Report progress:\n",
        "      print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "    \n",
        "    #Unpack this trainining batch from dataloader\n",
        "    #As we unpack dataloader, will also copy each tensor to GPU\n",
        "    #'batch' contains 3 pytorch tensors: [0]: input_ids, [1]: attention_mask, [2]: labels\n",
        "\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    #Always clear any previously calculated gradients before performing a backword pass.\n",
        "    #Pytorch dosen't do it automatically because accumulating gradient is convenient while\n",
        "    #working with RNN's.\n",
        "    model.zero_grad()\n",
        "\n",
        "    #Perform the forward pass (Evaluate the model on this training batch).\n",
        "    #This will return the loss (rather than the output) because we have provided the labels\n",
        "    outputs = model(b_input_ids,\n",
        "                   token_type_ids = None,\n",
        "                   attention_mask = b_input_mask,\n",
        "                   labels = b_labels)\n",
        "    \n",
        "    #The call model always returns a tuple, so we need to pull the loss value from tuple\n",
        "    loss = outputs[0]\n",
        "\n",
        "    #Accumulate the overall loss over all of the batches so that we can calculate the average\n",
        "    #loss at the end, \"loss\" is Tensor containing single value and the \".item()\" function just\n",
        "    #returns the python value from Tensor.\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    #Perform a backword pass to calculate the gradient:\n",
        "    loss.backward()\n",
        "\n",
        "    #Clip the norm of gradient to 1.0, this is to help prevent \"exploding gradient\" problem.\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    #Update the parameters and take a step using the computed gradient.\n",
        "    #The optimizer discates the \"update-rule\" --how the parameters are modified \n",
        "    #based on their gradients, the learning rate etc.\n",
        "    optimizer.step()\n",
        "\n",
        "    #Update the learning rate:\n",
        "    scheduler.step()\n",
        "\n",
        "  #Calculate the average loss over the training data:\n",
        "  avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  #Store the loss value for ploting the learning curve:\n",
        "  loss_values.append(avg_train_loss)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\" Average Training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\" Training epoch took : {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  #\n",
        "  #================== Validation ========================#\n",
        "  #\n",
        "\n",
        "  #After completion of each training epochs, measure our performance on validation set\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running validation.......\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  #Put the model in evaluation mode, during evaluation dropout layers behave differently\n",
        "  model.eval()\n",
        "\n",
        "  #Tracking variables:\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  #Evaluate data for each epochs:\n",
        "  for batch in validation_dataloader:\n",
        "    #Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    #unpack tuples from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    #Telling the model not to compute or store gradients, saving memory and speeding the validation\n",
        "    with torch.no_grad():\n",
        "      #forward pass calculate logit predictions\n",
        "      #This will return the logits rather than the loss because we have not provided labels\n",
        "      #token_type_ids are same as segment_ids which differenciate sentence 1 and 2 in 2-sentence tasks.\n",
        "      outputs = model(b_input_ids,\n",
        "                      token_type_ids = None,\n",
        "                      attention_mask = b_input_mask)\n",
        "\n",
        "\n",
        "    #Get logits output by the model. \"logits\" are the output values prior to applying to activation\n",
        "    #function like the softmax.\n",
        "    logits = outputs[0]\n",
        "\n",
        "    #Move logits and labels to CPU:\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    #Calculate the accuracy for this batch of test sentences\n",
        "    temp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    #Accumulate the totel accuracy\n",
        "    eval_accuracy += temp_eval_accuracy\n",
        "\n",
        "    #Track the number of batches:\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  #Report the final accuracy for this validation run:\n",
        "  print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(\"Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "#Print training completed\n",
        "print(\"========= Training Completed ================\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "========= Epoch 1/4 =========\n",
            "==== Training......\n",
            "Batch    40 of   241. Elapsed: 0:00:10.\n",
            "Batch    80 of   241. Elapsed: 0:00:19.\n",
            "Batch   120 of   241. Elapsed: 0:00:28.\n",
            "Batch   160 of   241. Elapsed: 0:00:37.\n",
            "Batch   200 of   241. Elapsed: 0:00:47.\n",
            "Batch   240 of   241. Elapsed: 0:00:56.\n",
            "\n",
            " Average Training loss: 0.49\n",
            " Training epoch took : 0:00:56\n",
            "\n",
            "Running validation.......\n",
            "Accuracy: 0.81\n",
            "Validation took: 0:00:02\n",
            "\n",
            "========= Epoch 2/4 =========\n",
            "==== Training......\n",
            "Batch    40 of   241. Elapsed: 0:00:09.\n",
            "Batch    80 of   241. Elapsed: 0:00:19.\n",
            "Batch   120 of   241. Elapsed: 0:00:28.\n",
            "Batch   160 of   241. Elapsed: 0:00:37.\n",
            "Batch   200 of   241. Elapsed: 0:00:46.\n",
            "Batch   240 of   241. Elapsed: 0:00:56.\n",
            "\n",
            " Average Training loss: 0.30\n",
            " Training epoch took : 0:00:56\n",
            "\n",
            "Running validation.......\n",
            "Accuracy: 0.82\n",
            "Validation took: 0:00:02\n",
            "\n",
            "========= Epoch 3/4 =========\n",
            "==== Training......\n",
            "Batch    40 of   241. Elapsed: 0:00:09.\n",
            "Batch    80 of   241. Elapsed: 0:00:19.\n",
            "Batch   120 of   241. Elapsed: 0:00:28.\n",
            "Batch   160 of   241. Elapsed: 0:00:37.\n",
            "Batch   200 of   241. Elapsed: 0:00:46.\n",
            "Batch   240 of   241. Elapsed: 0:00:56.\n",
            "\n",
            " Average Training loss: 0.19\n",
            " Training epoch took : 0:00:56\n",
            "\n",
            "Running validation.......\n",
            "Accuracy: 0.83\n",
            "Validation took: 0:00:02\n",
            "\n",
            "========= Epoch 4/4 =========\n",
            "==== Training......\n",
            "Batch    40 of   241. Elapsed: 0:00:09.\n",
            "Batch    80 of   241. Elapsed: 0:00:19.\n",
            "Batch   120 of   241. Elapsed: 0:00:28.\n",
            "Batch   160 of   241. Elapsed: 0:00:37.\n",
            "Batch   200 of   241. Elapsed: 0:00:46.\n",
            "Batch   240 of   241. Elapsed: 0:00:56.\n",
            "\n",
            " Average Training loss: 0.13\n",
            " Training epoch took : 0:00:56\n",
            "\n",
            "Running validation.......\n",
            "Accuracy: 0.82\n",
            "Validation took: 0:00:02\n",
            "========= Training Completed ================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pgBAMRsc1NY",
        "colab_type": "code",
        "outputId": "0d64788c-e5cb-47f1-a401-8bb1237657f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#for step, batch in enumerate(train_dataloader):\n",
        "#  print(step,batch)  #In this example 241 steps will contains data as per batch\n",
        "print(loss.item())\n",
        "#print(outputs[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.11515522748231888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIA6rCCYvcCW",
        "colab_type": "code",
        "outputId": "a10c1c23-23d3-4612-eae1-3cdfdc018b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style = 'darkgrid')\n",
        "\n",
        "sns.set(font_scale = 1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "#Plot the learning curve\n",
        "plt.plot(loss_values)\n",
        "plt.title(\"Learning Curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRERcyP8DB+quZqAtvh0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3E-p6_N_WZ8",
        "colab_type": "text"
      },
      "source": [
        "#Performance testing\n",
        "Now we will load the holdout dataset and prepare input (Preprocess), Then will evaluate using Mathews Correlation Cofficient (This is metric used by wider NLP communities to evaluate performance on Cola. (+1 is best and -1 is worst score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPzF0bovMPdZ",
        "colab_type": "text"
      },
      "source": [
        "###Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sNCWZa6AAhZ",
        "colab_type": "code",
        "outputId": "0657707d-07e4-4f22-e033-7dc28faf5d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_length, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0NU1ziGMC0q",
        "colab_type": "text"
      },
      "source": [
        "###Evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY_ZLRm_BW1t",
        "colab_type": "code",
        "outputId": "24b00ceb-98fa-4819-e479-08c1f0b80eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3IBM06ivGEG",
        "colab_type": "text"
      },
      "source": [
        "Accuracy on Cola benchmark is measured  using Matthews Correlation coffecient.\n",
        "\n",
        "For us classes are imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6CebwPHveKK",
        "colab_type": "code",
        "outputId": "0cf3514e-332e-4f8d-db15-0eb7c95b2317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Positive Samples %d of %d (%.2f%%)\" %(df.label.sum(), len(df.label), (df.label.sum()/len(df.label)*100)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Samples 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqlE1PoZwJQz",
        "colab_type": "code",
        "outputId": "1ad6ff24-ddea-4402-d04a-e650b735e518",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "#Evaluate each test batch using Matthew's correlation coffecient:\n",
        "print(\"Calculate Matthew Correlation Coffecient for each batch: \")\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  #The prediction for this batch are 2 column ndarray, pick the label with highest value that turn\n",
        "  #this into a list of 0s and 1s.\n",
        "  pred_lebel_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  #Calculate and store the coffecient for this batch:\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_lebel_i)\n",
        "  matthews_set.append(matthews)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculate Matthew Correlation Coffecient for each batch: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVCc0Lb-zdSI",
        "colab_type": "text"
      },
      "source": [
        "Final score will be based on the entire test set but let's see individual score for each batch\n",
        "\n",
        "All the batches will have 32 sentences in them except the last one which will have (516%32 = 4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGLUE9_UzJoO",
        "colab_type": "code",
        "outputId": "fd763bdf-c7d5-4bbb-8af3-30c46ca237ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.049286405809014416,\n",
              " -0.2548235957188128,\n",
              " 0.4040950971038548,\n",
              " 0.23372319715296222,\n",
              " 0.4133804997216296,\n",
              " 0.7410010097502685,\n",
              " 0.5269860393922079,\n",
              " 0.47519096331149147,\n",
              " 0.8320502943378436,\n",
              " 0.8805899139163632,\n",
              " 0.8459051693633014,\n",
              " 0.647150228929434,\n",
              " 0.8150678894028793,\n",
              " 0.7948717948717948,\n",
              " 0.3268228676411533,\n",
              " 0.49382916465843113,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZdPvK0d0CRD",
        "colab_type": "code",
        "outputId": "9773526c-3a41-48e5-962b-ba98eb7d3a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Combine the predictions for each batch into a single list of 0s and 1s\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis = 1).flatten()\n",
        "\n",
        "#Combine the correct labels for each batch into a single list:\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "#Calculate the MCC (Matthews Correlation Coffecient):\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print(\"MCC : %.3f\" %mcc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC : 0.540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhdQ3FqD2AIG",
        "colab_type": "text"
      },
      "source": [
        "#Saving and Loading the Fine-Tuned model\n",
        "\n",
        "Ref: run_glue.py "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ndovRMe1a2C",
        "colab_type": "code",
        "outputId": "02f48ce3-14aa-4ad7-d3c5-d7b38835d16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = '.model_save/'\n",
        "\n",
        "#Create output directory if needed:\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" %output_dir)\n",
        "\n",
        "#Save the trained model, configuration and tokenizer using \"save_pretrained()\".\n",
        "#They can be reloaded using \"from_pretrained()\".\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model #Take care of distributed parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "#Good prectice is to save training arguments together with trained model\n",
        "#torch.save(args, os.path.join(output_dir, \"training_args.bin\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to .model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('.model_save/vocab.txt',\n",
              " '.model_save/special_tokens_map.json',\n",
              " '.model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIuC_10f4dFN",
        "colab_type": "code",
        "outputId": "036ee45d-d8df-48ef-80d0-18491240352b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "#Let's check file size:\n",
        "!ls -l --block-size=k .model_save/\n",
        "\n",
        "#This shows largest file is model_weights\n",
        "print(\"Largest size is in model weights:\")\n",
        "!ls -l --block-size=M .model_save/pytorch_model.bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427960K\n",
            "-rw-r--r-- 1 root root      2K Feb  5 09:18 config.json\n",
            "-rw-r--r-- 1 root root 427719K Feb  5 09:18 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Feb  5 09:18 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Feb  5 09:18 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Feb  5 09:18 vocab.txt\n",
            "Largest size is in model weights:\n",
            "-rw-r--r-- 1 root root 418M Feb  5 09:18 .model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ5iaHE-45Dd",
        "colab_type": "code",
        "outputId": "4208cf67-1df4-4fc0-e238-7a3d6cda07b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "#Mount google drive to this Notebook Instance\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    232\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryrpjQBc7Gu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Copy the model file into the directory of google drive:\n",
        "!cp -r .model_save/ \"./drive/My Drive/Colab Notebooks/BERT Fine-Tuning/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-h9vOUy84Du",
        "colab_type": "text"
      },
      "source": [
        "Load the model back from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y1ZJdNb7vBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "#Load a trained model and vocabulary that is fine tuned:\n",
        "model = AutoModel.from_pretrained(output_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "#Copy the model to GPU:\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvfOietN-FqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}